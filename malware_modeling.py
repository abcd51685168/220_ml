# -*- coding: utf-8 -*-

from collections import defaultdict

from keras import backend as K
from keras.layers import Input, Embedding, Dense, merge
from keras.layers.convolutional import Convolution1D
from keras.layers.core import Dropout, Lambda
from keras.models import Model
from keras.models import Sequential


def equal_tokens(tokens, maxlen=10000):
    tokens = tokens[0:maxlen]
    if len(tokens) < maxlen:
        tokens = [0] * (maxlen - len(tokens)) + tokens
    return tokens


class Vocab(object):  # from 224d assignment 2-utils.py
    def __init__(self):
        self.word_to_index = {}
        self.index_to_word = {}
        self.word_freq = defaultdict(int)
        self.total_words = 0
        self.unknown = '<unk>'
        self.add_word(self.unknown, count=0)

    def add_word(self, word, count=1):
        if word not in self.word_to_index:
            index = len(self.word_to_index)
            self.word_to_index[word] = index
            self.index_to_word[index] = word
        self.word_freq[word] += count

    def construct(self, words):
        for word in words:
            self.add_word(word)
        self.total_words = float(sum(self.word_freq.values()))
        return len(self.word_freq)
        print '{} total words with {} uniques'.format(self.total_words, len(self.word_freq))

    def encode(self, word):
        if word not in self.word_to_index:
            word = self.unknown
        return self.word_to_index[word]

    def decode(self, index):
        return self.index_to_word[index]

    def __len__(self):
        return len(self.word_freq)


def sum_1d(X):
    return K.sum(X, axis=1)


def getconvmodel(filter_length, nb_filter):
    model = Sequential()
    model.add(Convolution1D(nb_filter=nb_filter,
                            input_shape=(10000, 50),
                            filter_length=filter_length,
                            border_mode='same',
                            activation='relu',
                            subsample_length=1))
    model.add(Lambda(sum_1d, output_shape=(nb_filter,)))
    # model.add(BatchNormalization(mode=0))
    model.add(Dropout(0.5))
    return model


def bag_of_convs_model(optimizer="adam", compile=True):
    main_input = Input(shape=(10000,), dtype='int32', name='main_input')
    embedding = Embedding(output_dim=50, input_dim=675, input_length=10000,
                          dropout=0)(main_input)

    conv1 = getconvmodel(2, 256)(embedding)
    conv2 = getconvmodel(3, 256)(embedding)
    conv3 = getconvmodel(4, 256)(embedding)
    conv4 = getconvmodel(5, 256)(embedding)

    merged = merge([conv1, conv2, conv3, conv4], mode="concat")

    middle = Dense(1024, activation='relu')(merged)
    middle = Dropout(0.5)(middle)

    middle = Dense(1024, activation='relu')(middle)
    middle = Dropout(0.5)(middle)

    output = Dense(35, activation='softmax')(middle)

    model = Model(input=main_input, output=output)
    if compile:
        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model
